[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Methoden des statistischen Lernens in den Wirtschaftswissenschaften",
    "section": "",
    "text": "Tag \n    Zeit \n    H√∂rsaal \n  \n \n\n  \n    Dienstag \n    09:45-10:00 \n    Raum 109 \n  \n\n\n\n\n\n\n\n\n\n\nWer will, darf sich gerne im Zulip-Chat Statistisches Lernen austauschen und Fragen posten."
  },
  {
    "objectID": "01-Linear-Models-Regr_shortend.html",
    "href": "01-Linear-Models-Regr_shortend.html",
    "title": "2¬† Resampling Methoden zum Erlenen von Regressionsfunktionen",
    "section": "",
    "text": "Sie k√∂nnen ‚Ä¶\n\ndie Probleme der Auswahl eines geeigneten Pr√§diktionsmodells an einem Beispiel benennen und erl√§utern. \ndie Grundidee der Validierungsdaten-Methode erl√§utern. \ndie Grundidee der k-fachen Kreuzvalidierung erl√§utern."
  },
  {
    "objectID": "01-Linear-Models-Regr_shortend.html#das-allgemeine-regressionsmodell",
    "href": "01-Linear-Models-Regr_shortend.html#das-allgemeine-regressionsmodell",
    "title": "2¬† Resampling Methoden zum Erlenen von Regressionsfunktionen",
    "section": "2.1 Das allgemeine Regressionsmodell",
    "text": "2.1 Das allgemeine Regressionsmodell\nDie einzelnen Pr√§diktorvariablen werden gerne kompakt zu einer multivariaten Pr√§diktorvariablen \\(X=(X_1,X_2,\\dots,X_p)\\) zusammengefasst; in unserem Benzinverbrauchsbeispiel also \\(X=(G,P,H,B).\\) So l√§sst sich das allgemeines Regressionsmodell schreiben als \\[\nY=f(X)+\\varepsilon,\n\\] wobei\n\n\\(f\\) den systematischen Zusammenhang zwischen der Zielvariable \\(Y\\) und den Pr√§diktorvariablen \\(X\\) beschreibt und\n\\(\\varepsilon\\) ein Fehlerterm ist, dessen bedingter Mittelwert gegeben \\(X\\) gleich null ist, \\[\nE(\\varepsilon|X)=0.\n\\]\n\nDaraus ergibt sich folgender Zusammenhang zwischen der allgemeinen Regressionsfunktion \\(f\\) und dem bedingten Mittelwert von \\(Y\\) gegeben \\(X\\): \\[\nE(Y|X)=E(f(X)+\\varepsilon|X)=f(X)\n\\] Die Funktion \\(f\\) beschreibt also den bedingten Mittelwert von \\(Y\\) gegeben \\(X\\). Ziel ist es nun, die Regressionsfunktion \\(f\\) aus den Daten zu erlernen.\n\nAbbildung Figure¬†2.2 zeigt ein Beispiel von \\(50\\) simulierten Daten (k√ºnstlich erzeugte Fake-Daten). Der Plot legt nahe, dass man das Einkommen mit Hilfe der Ausbildungsjahre vorhersagen kann. Normalerweise ist die wahre Funktion \\(f\\), welche die Verbindung zwischen \\(Y\\) und \\(X\\) beschreibt, unbekannt und muss aus den Daten gesch√§tzt werden. Da es sich hier um simulierte Daten handelt, k√∂nnen wir den Graph der Funktion \\(f\\) als blaue Linie plotten. Einige der \\(50\\) Beobachtungspunkte \\((X,Y)\\) liegen √ºber der Regressionsfunktion \\(f(X)\\), andere darunter. Im Gro√üen und Ganzen haben die Fehlerterme einen Mittelwert von Null.\n\n\n\n\n\nFigure¬†2.2: Simulierte (k√ºnstlich erzeugte) Daten zur Veranschaulichung einer allgemeinen, univariaten Regressionsbeziehung.\n\n\n\n\nAbbildung Figure¬†2.3 zeigt ein simuliertes Beispiel einer allgemeinen, bivariaten Regressionsbeziehung \\[\nY=f(X)+\\varepsilon\\quad\\text{mit}\\quad X=(X_1,X_2).\n\\]\n\n\n\n\n\nFigure¬†2.3: Veranschaulichung einer allgemeinen, bivariaten Regressionsbeziehung.\n\n\n\n\n\n2.1.1 Der Pr√§diktionsfehler\n\nSei \\(\\hat{f}\\) eine Sch√§tzung der unbekannten Regressionsfunktion \\(f,\\) gesch√§tzt z.B. mit Hilfe der Polynomregression in Section¬†2.1.2. Gegeben der Sch√§tzung \\(\\hat{f}\\) und gegeben bestimmter Pr√§diktorvariablen \\[\nX=(X_1,X_2,\\dots,X_p)\n\\] (z.B. Gewicht, PS und Hubraum eines neuen Autos), k√∂nnen wir die dazugeh√∂rige, abh√§ngige Variable \\(Y\\) vorhersagen:\n \\[\nY\\approx \\hat{Y}=\\hat{f}(X).\n\\] \nDie Genauigkeit der Vorhersage von \\(\\hat{Y}\\) f√ºr \\(Y\\) h√§ngt von zwei verschiedenen Pr√§diktionsfehlergr√∂√üen ab:\n\nReduzierbarer Pr√§diktionsfehler aufgrund des Sch√§tzfehlers in \\(\\hat{f}\\). Eine genauere Sch√§tzung kann diesen Fehler reduzieren.\nNicht reduzierbarer Pr√§diktionsfehler aufgrund des Fehlerterms \\(\\varepsilon\\). Das ist der Fehler, den wir selbst bei perfekter Sch√§tzung von \\(f\\) nicht reduzieren k√∂nnen.\n\nDer nicht reduzierbare Fehler \\(\\varepsilon\\) enth√§lt alle nicht messbaren und nicht gemessenen Variablen, die ebenfalls einen Einfluss auf \\(Y\\) haben. Und da wir diese Variablen nicht messen k√∂nnen, k√∂nnen wir sie auch nicht verwenden, um \\(f\\) zu sch√§tzen.\n\nSei nun \\(\\hat{f}\\) eine gegebene Sch√§tzung von \\(f\\) und seien \\(X\\) gegeben Werte der Pr√§diktorvariablen welche die Vorhersage \\(\\hat{Y}=\\hat{f}(X)\\) ergeben. Nehmen wir nun f√ºr einen Moment an, dass \\(\\hat{f}\\) und \\(X\\) gegeben und fest (also nicht zuf√§llig) sind, dann \\[\n\\begin{align*}\nE\\left[(Y-\\hat{Y})^2\\right]\n&=E\\Big[(\\overbrace{f(X)+\\varepsilon}^{=Y} - \\overbrace{\\hat{f}(X)}^{=\\hat{Y}})^2\\Big]\\\\\n&=E\\left[\\left((f(X)-\\hat{f}(X)\\right)^2+2\\left((f(X)-\\hat{f}(X)\\right)\\varepsilon+\\varepsilon^2\\right]\\\\\n&=\\underbrace{\\left((f(X)-\\hat{f}(X)\\right)^2}_{\\text{reduzierbar}}+\\underbrace{\\operatorname{Var}(\\varepsilon)}_{\\text{nicht reduzierbar}}\n\\end{align*}\n\\]\n\nDer mittlere quadratische Pr√§diktionsfehler \\(E\\left[(Y-\\hat{Y})^2\\right]\\) l√§sst sich also in eine reduzierbare und eine nicht reduzierbare Fehlerkomponente zerlegen.\n\n\n\n\n\n\n2.1.2 Polynomregression\nDas Polynomregressionsmodell \\[\nf_p(X) = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_1^2 + \\dots + \\beta_p X_1^p  \n\\] ist eine M√∂glichkeit, die allgemeine Regressionsfunktion \\(f(X)=E(Y|X)\\) zu sch√§tzen (lernen).\nDie Polynomstruktur erlaubt es, die nicht linearen Beziehungen zwischen der Zielvariablen und den Pr√§diktorvariablen in unserem Benzinverbrauchsproblem (siehe Abbildung Figure¬†2.1) zu ber√ºcksichtigen.\nSo kann, zum Beispiel, der nicht lineare Zusammenhang zwischen Verbrauch und Leistung PS sehr flexibel als Polynomfunktion modelliert werden: \\[\n\\texttt{Verbrauch}(\\texttt{PS}) = \\beta_0 + \\beta_1 \\texttt{PS} + \\beta_2 \\texttt{PS}^2 + \\dots + \\beta_p \\texttt{PS}^p\n\\] Je h√∂her der Grad \\(p\\) des Polynoms, desto flexibler ist ein Polynomregressionsmodell.\nDas Polynomregressionsmodell ist jedoch f√ºr alle Polynomgrade \\(p\\) ein lineares Regressionsmodell, denn es ist linear bez√ºglich der Modellparameter \\(\\beta_0, \\beta_1, \\dots, \\beta_p\\).\nF√ºr einen gegebenen Polynomgrad \\(p\\), lassen sich die unbekannten Modelparameter einfach mit Hilfe der Methode der kleinsten Quadrate sch√§tzen: \\[\n\\hat{f}_p(X) = \\hat\\beta_0 + \\hat\\beta_1 X_1 + \\hat\\beta_2 X_1^2 + \\dots + \\hat\\beta_p X_1^p  \n\\] mit \\[\n\\hat\\beta = (X'X)^{-1}X'Y,\n\\]\nwobei \\[\n\\begin{align*}\n\\hat\\beta=\\left(\n  \\begin{matrix}\n  \\hat{\\beta}_0\\\\\n  \\hat{\\beta}_1\\\\\n  \\vdots\\\\\n  \\hat{\\beta}_p\n  \\end{matrix}\n\\right),\n\\quad\nX=\\left(\\begin{matrix}\n  1     &x_{11}&x_{11}^2&\\dots   & x_{11}^p\\\\\n  \\vdots&\\vdots&\\vdots  & \\ddots & \\vdots  \\\\\n  1     &x_{n1}&x_{n1}^2&\\dots   & x_{n1}^p\\\\\n  \\end{matrix}\\right)\n\\quad\n\\text{und}\n\\quad\nY=\\left(\n  \\begin{matrix}\n  y_1\\\\\n  \\vdots\\\\\n  y_n\n  \\end{matrix}\n\\right).\n\\end{align*}\n\\]\n\n## Polynom Regressionen\npolreg_1 <- lm(Verbrauch ~ poly(PS, degree = 1, raw=TRUE), data = Auto_df)\npolreg_2 <- lm(Verbrauch ~ poly(PS, degree = 2, raw=TRUE), data = Auto_df)\npolreg_5 <- lm(Verbrauch ~ poly(PS, degree = 5, raw=TRUE), data = Auto_df)\n## Data-Frame zum Abspeichern der Pr√§diktionen\nplot_df       <- tibble(\"PS\" = seq(45, 250, len=50))\n## Abspeichern der Pr√§diktionen\nplot_df$fit_1 <- predict(polreg_1, newdata = plot_df)\nplot_df$fit_2 <- predict(polreg_2, newdata = plot_df)\nplot_df$fit_5 <- predict(polreg_5, newdata = plot_df)\n## Ploten\nplot(Verbrauch ~ PS, data = Auto_df, ylim=c(2,20),\n     xlab=\"Leistung (PS)\", pch=21, col=\"gray\", bg=\"gray\", cex=1.5)\nwith(plot_df, lines(x = PS, y = fit_1, lwd=2, col=\"orange\"))\nwith(plot_df, lines(x = PS, y = fit_2, lwd=2, col=\"blue\"))\nwith(plot_df, lines(x = PS, y = fit_5, lwd=2, col=\"darkgreen\"))\nlegend(\"topright\", lty=c(NA,1,1,1), pch=c(21,NA,NA,NA), \n       col=c(\"gray\",\"orange\",\"blue\",\"darkgreen\"), pt.bg=\"gray\", pt.cex=1.5,\n       legend=c(\"Datenpunkte\", \"Grad 1\", \"Grad 2\", \"Grad 5\"), bty=\"n\")\n\n\n\n\nPolynom Regression bei verschiedenen Polynomgraden \\(p\\).\n\n\n\n\n\n2.1.2.1 √úberanpassung\nZus√§tzlich zur Wahl der Modellparameter \\(\\hat{\\beta}_0, \\hat{\\beta}_1, \\dots, \\hat{\\beta}_p\\) besteht hier nun das Problem der Wahl des Grades \\(p\\) des Polynoms als weiteren Modellparameter \\[\ny_i=\\hat{\\beta}_0 + \\hat{\\beta}_1 x_{i1} + \\hat{\\beta}_2 x_{i2}^2 + \\dots + \\hat{\\beta}_p x_{ip}^p + e_i\n\\] Wenn man jedoch versucht, alle Modellparameter (also \\(\\hat{\\beta}_0, \\hat{\\beta}_1, \\dots, \\hat{\\beta}_p\\) und \\(p\\)) durch Minimieren der Trainingsdaten-RSS \\[\n\\operatorname{RSS}\\equiv\\operatorname{RSS}(\\hat{\\beta}_0, \\hat{\\beta}_1, \\dots, \\hat{\\beta}_p,p)=e_1^2 + e_2^2 + \\dots + e_n^2\n\\] zu sch√§tzen, so ergibt sich ein Problem das als √úberanpassung (Overfitting) bekannt ist (siehe Abbildung Figure¬†2.4). Das Polynomregressionsmodell ist so flexibel, dass es den einzelnen Trainingsdaten \\((x_i,y_i)\\) folgen kann. Eine √úberangepassung an die Trainingsdaten f√ºhrt jedoch notwendigerweise zu einer Verschlechterung der Vorhersageg√ºte bez√ºglich neuer Daten.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†2.4: Polynom Regression und die Wahl des Polynomgrades \\(p\\) durch Minimierung der Trainingsdaten-RSS. (Eine schlechte Idee).\n\n\n\n\n\n\nProblem der Methode der kleinsten Quadrate\n\nDas Minimieren der Residuen-Quadratsumme (Residual Sum of Squares, RSS) is √§quivalent zum minimieren des mittleren quadratischen Fehlers bzgl. der Trainingsdaten \\[\n\\frac{1}{n}\\operatorname{RSS}_p=\\frac{1}{n}\\sum_{i=1}^n\\left(y_i - \\hat{f}_p(x_i)\\right)^2,\n\\] wobei \\((y_i,x_i),\\) \\(i=1,\\dots,n\\) hier die beobachteten Trainingsdaten bezeichnet.\nF√ºr hohe Polynomgrade \\(p\\) wird \\(\\hat{f}_p(x_i)\\) sehr flexibel, sodass \\[\ny_i \\approx \\hat{f}_p(x_i).\n\\] Dies erkl√§rt die Beobachtung, dass \\(\\operatorname{RSS}_p\\) monoton fallend ist in \\(p,\\) also \\[\n\\operatorname{RSS}_p\\geq \\operatorname{RSS}_{p'}\\quad\\text{f√ºr}\\quad p < p'.\n\\]\n\nDamit erlernt \\(\\hat{f}_p(x_i)\\) von \\(y_i\\)\n\nden erw√ºnschten Teil \\(f(x_i)\\)\naber auch den unerw√ºnschten Fehlerterm \\(\\varepsilon_i\\) üò≠\n\nDas erlernte Model \\(\\hat{f}_p(x_i)\\) ist fehlerbehaftet, d.h. \\(\\hat{f}_p(x_i)\\not\\approx f(x_i).\\)\n\n\n\nMittlerer quadratischer Fehlers bzgl. der Testdaten\nUm eine √úberanpassung an die Trainingsdaten zu verhindern, m√ºss man die Pr√§diktionsg√ºte von \\(\\hat{f}_p(x_i)\\) mit Hilfe neuer Testdaten √ºberpr√ºfen.\nEine h√§ufig betrachtete Gr√∂√üe ist der mittlere quadrierte Pr√§diktionsfehler (mean squared prediction error, MSPE) \\[\n\\operatorname{MSPE}_{Test}=\\frac{1}{m}\\sum_{i=1}^m\\left(y^{Test}_i - \\hat{f}_p(x^{Test}_i)\\right)^2,\n\\] wobei\n\n\\((y^{Test}_i,x^{Test}_i),\\) \\(i=1,\\dots,m\\) die Testdaten bezeichnet,\n\\(\\hat{f}_p\\) jedoch auf Basis der Trainingsdaten berechnet wurde.\n\nDie Trainings- und Testdaten m√ºssen voneinander unabh√§ngig sein, sodass \\[\n\\begin{align*}\n&\\operatorname{MSPE}^{Test}_p\n=\\frac{1}{m}\\sum_{i=1}^m\\left(y^{Test}_i - \\hat{f}_p(x^{Test}_i)\\right)^2\\\\\n&=\\frac{1}{m}\\sum_{i=1}^m\\left((f(x^{Test}_i)+\\varepsilon^{Test}_i) - \\hat{f}_p(x^{Test}_i)\\right)^2\\\\\n&=\\underbrace{\\frac{1}{m}\\sum_{i=1}^m\\left(f(x^{Test}_i)-\\hat{f}_p(x^{Test}_i)\\right)^2}_{\\approx E\\left(\\left(f(X)-\\hat{f}_p(X)\\right)^2\\right)}\n+\\underbrace{\\frac{1}{m}\\sum_{i=1}^m\\left(\\varepsilon_i^{Test}\\right)^2}_{\\approx \\operatorname{Var}(\\varepsilon)}\n-\\underbrace{\\frac{1}{m}\\sum_{i=1}^m\\varepsilon_i^{Test}\\hat{f}_p(x^{Test}_i)}_{\\approx 0}\n\\end{align*}\n\\]\nDie Minimierung von \\(\\operatorname{MSPE}^{Test}_p\\) bzgl \\(p\\) entspricht also (approximativ for gro√üe \\(m\\)) einer Minimierung von \\[\nE\\left(\\left(f(X)-\\hat{f}_p(X)\\right)^2\\right).\n\\]\n\\(\\operatorname{MSPE}^{Test}_p\\) stellt damit ein korrigiertes kleinste Quadrate Kriterium dar, welches eine Anpassung an die Fehlerterm \\(\\varepsilon_i\\) verhindert."
  },
  {
    "objectID": "01-Linear-Models-Regr_shortend.html#resampling-methoden-zur-modellauswahl",
    "href": "01-Linear-Models-Regr_shortend.html#resampling-methoden-zur-modellauswahl",
    "title": "2¬† Resampling Methoden zum Erlenen von Regressionsfunktionen",
    "section": "2.2 Resampling Methoden zur Modellauswahl",
    "text": "2.2 Resampling Methoden zur Modellauswahl\n\nMaschinelles Lernen versus Strukturelle Modelle\n\n\n\n\n\n2.2.1 Die Validierungsdaten-Methode\nDa die Minimierung der Trainingsdaten-RSS schnell zu einem Problem der √úberanpassung f√ºhrt, ben√∂tigen wir eine alternative Methode, um die G√ºte des gesch√§tzten Modells zu pr√ºfen. Die einfachste Idee ist dabei die beobachteten Daten \\[\n(x_i,y_i),\\quad i\\in\\mathcal{I}=\\{1,2,\\dots,n\\}\n\\] in einen Satz von Trainingsdaten \\[\n\\left\\{(x_{1}^{Train},y_{1}^{Train}),\\dots,(x_{n_{Train}}^{Train},y_{n_{Train}}^{Train})\\right\\}=\\{(x_i,y_i):i\\in\\mathcal{I}^{Train}\\}\n\\] und einen separaten (disjunkten) Satz von Validierungsdaten \\[\n\\left\\{(x_{1}^{Valid},y_{1}^{Valid}), \\dots,(x_{n_{Valid}}^{Valid},y_{n_{Valid}}^{Valid})\\right\\}=\\{(x_i,y_i):i\\in\\mathcal{I}^{Valid}\\}\n\\] zu teilen mit \\[\n\\overbrace{|\\mathcal{I}|}^{=n}=\\overbrace{|\\mathcal{I}^{Train}|}^{=n_{Train}}+\\overbrace{|\\mathcal{I}^{Valid}|}^{=n_{Valid}},\n\\] sodass \\(\\mathcal{I}^{Train}\\cap\\mathcal{I}^{Valid} = \\emptyset\\)\nFolgender Code-Schnipsel erm√∂glicht solch eine (zuf√§llige) Aufteilung der Daten in Trainings- und Validierungsdaten:\n\nn        <- nrow(Auto_df) # Stichprobenumfang\nn_Train  <- 200           # Stichprobenumfang der Trainingsdaten\nn_Valid  <- n - n_Train   # Stichprobenumfang der Validierungsdaten\n\n## Index-Mengen zur Auswahl der \n## Trainings- und Validierungsdaten\nI_Train  <- sample(x = 1:n, size = n_Train, replace = FALSE)\nI_Valid  <- c(1:n)[-I_Train]\n\n## Trainingsdaten \nAuto_Train_df <- Auto_df[I_Train, ]\n## Validierungsdaten \nAuto_Valid_df <- Auto_df[I_Valid, ]\n\nObschon die Validierungsdaten-Methode auf alle Regressionsmodelle angewandt werden kann, veranschaulichen wir im Folgenden die Methode anhand der Polynomregression.\nDie Aufteilung der Daten in Trainings- und Validierungsdaten erm√∂glicht uns nun ein zweistufiges Verfahren:\nSchritt 1: Mit Hilfe der Trainingsdaten wird das Polynomregressionsmodell gesch√§tzt: \\[\n\\begin{align*}\ny^{Train}_i\n%&=\\hat{f}^{Train}_p(x_i^{Train}) + e_i^{Train}\\\\\n&=\\hat{\\beta}_0^{Train} + \\hat{\\beta}_1^{Train} x_{i}^{Train} + \\hat{\\beta}_2^{Train} (x_{i}^{Train})^2 + \\dots + \\hat{\\beta}_p^{Train} (x_{i}^{Train})^p + e_i^{Train}\n\\end{align*}\n\\] Code-Schnipsel Beispiel:\n\nTrain_polreg <- lm(Verbrauch ~ poly(PS, degree = p, raw=TRUE), data = Auto_Train_df)\n\nSchritt 2: Mit Hilfe der Validierungsdaten wird das gesch√§tzte Polynomregressionsmodell validiert: \\[\n\\begin{align*}\n\\hat{y}^{Valid}_i\n%&=\\hat{f}_p^{Train}(x_i^{Valid})+ e_i^{Valid}\\\\\n&=\\hat{\\beta}_0 + \\hat{\\beta}_1^{Train} x_{i}^{Valid} + \\hat{\\beta}_2^{Train} (x_{i}^{Valid})^2 + \\dots + \\hat{\\beta}_p^{Train} (x_{i}^{Valid})^p,\n\\end{align*}\n\\] indem man den mittleren quadratischen Pr√§diktionsfehler (Mean Squared Prediction Error MSPE) berechnet: \\[\n\\begin{align*}\n\\text{MSPE}\n&=\\frac{1}{n_{Valid}}\\text{RSS}_{Valid}\\\\\n&=\\frac{1}{n_{Valid}}\\left((y_1^{Valid} - \\hat{y}_1^{Valid})^2 +\\dots + (y_{n_{Valid}}^{Valid} - \\hat{y}_{n_{Valid}}^{Valid})^2\\right)\n\\end{align*}\n\\] Code-Schnipsel Beispiel:\n\ny_fit_Valid   <- predict(Train_polreg, newdata = Auto_Valid_df)\nRSS_Valid     <- sum( (Auto_Valid_df$Verbrauch - y_fit_Valid)^2 )\nMSPE          <- RSS_Valid / n_Valid\n\nMan wiederholt obige Schritte f√ºr eine Auswahl von verschiedenen Polynomgraden \\(p=1,2,\\dots,p_{\\max}\\), z.B. \\(p_{\\max}=10\\), und berechnet f√ºr jeden dieser F√§lle den \\(\\operatorname{MSPE}\\), also: \\[\n\\operatorname{MSPE}\\equiv\\operatorname{MSPE}(\\hat{\\beta}_0, \\hat{\\beta}_1, \\dots, \\hat{\\beta}_p,p),\\quad\\text{f√ºr jedes}\\quad p=1,2,\\dots,p_{\\max}\n\\] Der \\(\\operatorname{MSPE}\\) ist eine Sch√§tzung des wahren, unbekannten mittleren quadratischen Pr√§diktionsfehlers \\(E\\left[(Y-\\hat{Y})^2\\right]\\),\n\\[\n\\operatorname{MSPE}(\\hat{\\beta}_0, \\hat{\\beta}_1, \\dots, \\hat{\\beta}_p,p)\\approx E\\left[(Y-\\hat{Y})^2\\right].\n\\] Die Minimierung des \\(\\operatorname{MSPE}\\) √ºber verschiedene Werte des Polynomgrades \\(p=1,2,\\dots\\) erlaubt es uns den reduzierbaren Pr√§diktions-Fehler der Polynomregression zu minimieren.\nFolgender R-Code verbindet nun alle Schritte und berechnet den \\(\\operatorname{MSPE}\\) f√ºr verschiedene Werte des Polynomgrades \\(p\\). Dasjenige Modell, welches den \\(\\operatorname{MSPE}\\) minimiert, ist laut der Daten das beste Pr√§diktionsmodell.\n\nset.seed(31)\n##\nn        <- nrow(Auto_df) # Stichprobenumfang\nn_Train  <- 200           # Stichprobenumfang der Trainingsdaten\nn_Valid  <-n - n_Train    # Stichprobenumfang der Validierungsdaten\n\n## Index-Mengen zur Auswahl der \n## Trainings- und Validierungsdaten\nI_Train  <- sample(x = 1:n, size = n_Train, replace = FALSE)\nI_Valid  <- c(1:n)[-I_Train]\n\n## Trainingsdaten \nAuto_Train_df <- Auto_df[I_Train, ]\n## Validierungsdaten \nAuto_Valid_df <- Auto_df[I_Valid, ]\n\np_max         <- 6\nMSPE          <- numeric(p_max)\nfit_plot      <- matrix(NA, 50, p_max)\nfor(p in 1:p_max){\n  ## Schritt 1\n  Train_polreg <- lm(Verbrauch ~ poly(PS, degree = p, raw=TRUE), \n                     data = Auto_Train_df)\n  ## Schritt 2\n  y_fit_Valid   <- predict(Train_polreg, newdata = Auto_Valid_df)\n  RSS_Valid     <- sum( (Auto_Valid_df$Verbrauch - y_fit_Valid)^2 )\n  MSPE[p]       <- RSS_Valid / n_Valid\n  ## Daten f√ºr's plotten\n  fit_plot[,p] <- predict(Train_polreg, newdata = plot_df)\n}\n\n\n\n\n\n\nPolynom Regression und die Wahl des Polynomgrades \\(p\\) durch Minimierung des mittleren quadratischen Pr√§diktionsfehler MSPE.\n\n\n\n\n\nAchtung: Auch eine Modellauswahl ist fehlerhaft und stellt lediglich eine Sch√§tzung (mit Sch√§tzfehlern) des besten Pr√§diktionsmodelles innerhalb der betrachteten Klasse von Pr√§diktionsmodellen (hier Polynomregressionen) dar.\n\nAbbildung Figure¬†2.5 zeigt jedoch ein Problem der Validierungsdaten-Methode. Die Trainingsdaten und die Validierungsdaten haben kleinere Stichprobenumf√§nge (\\(n_{Train}<n\\) und \\(n_{Valid}<n\\)) was zu einer erh√∂hten Sch√§tzgenauigkeit in der MSPE-Sch√§tzung f√ºhrt.\n\n\n\n\n\nFigure¬†2.5: Zehn verschiedene MSPE-Berechnungen basierend auf zehn verschiedenen, zuf√§lligen Aufteilungen der Daten in Trainings- und Validierungsdaten.\n\n\n\n\n\n\n2.2.2 k-Fache Kreuzvalidierung\nDie \\(k\\)-fache (z.B. \\(k=5\\) oder \\(k=10\\)) Kreuzvalidierung ist eine Vorgehensweise zur Bewertung der Leistung einer Sch√§tzprozedur (Algorithmus) im Kontext des maschinellen Lernens. Als Sch√§tzprozedur verwenden wir wieder das Beispiel der Polynomregression mit unbekanntem Polynomgrad \\(p\\), welcher zusammen mit den Modellparametern \\(\\beta_0,\\beta_1,\\dots,\\beta_p\\) aus den Daten erlernt werden muss.\nDie \\(k\\)-fache Kreuzvalidierung stellt eine Verbesserung der Validierungsdaten-Methode dar, da sie faktisch die Stichprobenumf√§nge in den Trainingsdaten und Validierungsdaten erh√∂ht. Wie bei der Validierungsdaten-Methode wird der Datensatz in Trainings- und Validierungsdaten aufgeteilt ‚Äì jedoch \\(k\\)-fach. Abbildung Figure¬†2.6 zeigt ein Beispiel der Datenaufteilung bei der \\(5\\)-fachen Kreuzvalidierung.\n\n\n\n\n\nFigure¬†2.6: Datenaufteilung in Trainings- und Validierungsdaten bei der \\(5\\)-fachen Kreuzvalidierung.\n\n\n\n\n\nFolgender Code-Schnipsel erm√∂glicht eine (zuf√§llige) Aufteilung der Daten in \\(k\\) verschiedene Trainings- und Validierungsdaten:\n\nn      <- nrow(Auto_df) # Stichprobenumfang\nk      <- 5             # 5-fache Kreuzvalidierung\n\n## Index zur Auswahl k verschiedener  \n## Trainings- und Validierungsdaten:\nfolds  <- sample(x = 1:k, size = n, replace=TRUE)\n\n## Trainingsdaten im j-ten (j=1,2,...,k) Durchgang\nAuto_df[folds != j,]\n## Validierungsdaten im j-ten (j=1,2,...,k) Durchgang\nAuto_df[folds == j,]\n\n\nF√ºr jede der \\(k\\) Datenaufteilungen wird der \\(\\operatorname{MSPE}\\) berechnet. Der Mittelwert dieser MSPE-Werte wird h√§ufig als \\(\\operatorname{CV}_{(k)}\\) Wert (crossvalidation score) bezeichnet \\[\n\\operatorname{CV}_{(k)}=\\frac{1}{k}\\sum_{j=1}^k\\operatorname{MSPE}_j\n\\]\nDer \\(\\operatorname{CV}_{(k)}\\)-Wert stellt eine im Vergleich zur Validierungsdaten-Methode verbesserte Sch√§tzung des unbekannten mittleren quadratischen P√§diktionsfehlers \\(\\operatorname{CV}_{(k)}\\approx E[(Y-\\hat{Y})^2]\\) dar. Die Modellauswahl folgt also auch hier mittels Minimierung des \\(\\operatorname{CV}_{(k)}\\)-Wertes √ºber die verschiedene Werte des Polynomgrades \\(p=1,2,\\dots\\).\n\nWahl von \\(k\\): In der Praxis haben sich die Werte \\(k=5\\) und \\(k=10\\) etabliert, da diese Gr√∂√üenordnunen einen guten Kompromiss zwischen der Varianz und der Verzerrung des Sch√§tzers \\(\\operatorname{CV}_{(k)}\\) f√ºr \\(E[(Y-\\hat{Y})^2]\\) darstellen."
  },
  {
    "objectID": "01-Linear-Models-Regr_shortend.html#anwendung-vorhersage-des-benzinverbrauchs-fraud-detection",
    "href": "01-Linear-Models-Regr_shortend.html#anwendung-vorhersage-des-benzinverbrauchs-fraud-detection",
    "title": "2¬† Resampling Methoden zum Erlenen von Regressionsfunktionen",
    "section": "2.3 Anwendung: Vorhersage des Benzinverbrauchs (Fraud Detection)",
    "text": "2.3 Anwendung: Vorhersage des Benzinverbrauchs (Fraud Detection)\n\n\n\n\n\nFigure¬†2.7: Hauptursache f√ºr die hohe, gesundheitsgef√§hrdende NO2-Belastung der Stadtluft sind Diesel-Fahrzeuge (Foto von David Lee).\n\n\n\n\nNun haben wir das Werkzeug, um die nicht linearen Zusammenh√§nge zwischen der Zielvariable \\(Y=\\)Verbrauch und den Pr√§diktorvariablen \\(G=\\)Gewicht, \\(P=\\)PS und \\(H=\\)Hubraum im Datensatz Auto_df zu ber√ºcksichtigen (siehe Abbildung Figure¬†2.1) und allein mit Hilfe der Daten zu erlernen. Wir folgen hier der Herangehensweise des maschinellen Lernens und lassen die Daten f√ºr sich selbst sprechen.\nDa Abbildung Figure¬†2.1 sehr √§hnliche Zusammenh√§nge zwischen der Zielvariable \\(Y=\\)Verbrauch und den Pr√§diktorvariablen \\(G=\\)Gewicht, \\(P=\\)PS und \\(H=\\)Hubraum vermuten l√§sst, betrachten wir zun√§chst ein vereinfachtest Polynomregressionsmodell, bei dem f√ºr alle Pr√§diktorvariablen der gleiche Polynomgrad \\(p\\) verwendet wird.\n\\[\n\\begin{align*}\nY_i = \\beta_0 + \\notag\n& \\beta^G_{1} G_i + \\beta^G_{2} G_i^2 + \\dots + \\beta^G_{p} G_i^p + \\\\\n& \\beta^P_{1} P_i + \\beta^P_{2} P_i^2 + \\dots + \\beta^P_{p} P_i^p +  \\\\\n& \\beta^H_{1} H_i + \\beta^H_{2} H_i^2 + \\dots + \\beta^H_{p} H_i^p +  \\varepsilon_i\n\\end{align*}\n\\]\nFolgender R-Code (Algorithmus) erlernt aus den Daten, mit Hilfe der \\(5\\)-fachen Kreuzvalidierung \\(\\operatorname{CV}_{(5)}\\approx E[(Y-\\hat{Y})^2]\\), den optimalen Polynomgrad \\(p\\).\n\nset.seed(8)             # Seed f√ºr den Zufallsgenerator\n\nn      <- nrow(Auto_df) # Stichprobenumfang\nk      <- 5             # 5-fache Kreuzvalidierung\np_max  <- 5             # Maximaler Polynomgrad\n\nfolds     <- sample(x = 1:k, size = n, replace=TRUE)\n\n## Container f√ºr die MSPE-Werte \n## f√ºr alle j=1,...,k Kreuzvalidierungen und \n## f√ºr alle p=1,...,p_max Polynomgrade\nMSPE <- matrix(NA, nrow = k, ncol = p_max,\n                    dimnames=list(NULL, paste0(\"p=\",1:p_max)))\n\nfor(p in 1:p_max){\n  for(j in 1:k){\n  ## Modelsch√§tzung auf Basis j-ten Traininsdaten Auto_df[folds != j,]\n  poly_fit <- lm(Verbrauch ~\n                   poly(Gewicht,        degree = p, raw = TRUE) +\n                   poly(PS,             degree = p, raw = TRUE) +\n                   poly(Hubraum,        degree = p, raw = TRUE),\n                 data=Auto_df[folds != j,])\n    ## Pr√§diktion  auf Basis j-ten Validierungsdaten Auto_df[folds == j,]\n    pred          <- predict(poly_fit, newdata = Auto_df[folds == j,])\n    ## \n    MSPE[j,p] <- mean( (Auto_df$Verbrauch[folds==j] - pred)^2 )\n  }\n}\n\n## CV-Wert f√ºr alle p=1,...,p_max Polynomgrade \nCV_k <- colMeans(MSPE)\n\n## Plotten\nplot(y = CV_k, x = 1:length(CV_k), pch=21, col=\"black\", bg=\"black\", \n     type='b', xlab=\"Polynomgrad p\", ylab=expression(CV[(5)]), log=\"y\")\npoints(y = CV_k[which.min(CV_k)],\n       x = c(1:length(CV_k))[which.min(CV_k)],\n       col = \"red\", bg = \"red\", pch = 21)\n\n\n\n\nAuch der \\(5\\)-fache Kreuzvalidierungswert \\(\\operatorname{CV}_{(5)}\\) ist lediglich eine zufallsbehaftete Sch√§tzung des unbekannten mittleren quadratischen Pr√§diktionsfehlers \\(E[(Y-\\hat{Y})^2]\\). Um eine Idee von der Pr√§zision und Stabilit√§t der Modellauswahl mittels der Minimierung von \\(\\operatorname{CV}_{(5)}\\) zu bekommen, k√∂nnen wir die zuf√§lligen, \\(5\\)-fachen Aufteilungen der Daten in Trainins- und Validierungsdaten wiederholen und den Effekt alternativer Datenaufteilungen betrachten. Abbildung Figure¬†2.8 zeigt, dass die Minimierung des Kreuzvalidierungswertes \\(\\operatorname{CV}_{(5)}\\) auch in Wiederholungen h√§ufig das Modell mit Polynomgrad \\(p=2\\) ausw√§hlt. Der Polynomgrad \\(p=2\\) scheint also eine vertauensw√ºrde Modellauswahl darzustellen.\n\n\n\n\n\nFigure¬†2.8: Zehn verschiedene \\(\\operatorname{CV}_{(k)}\\)-Berechnungen basierend auf zehn verschiedenen, zuf√§lligen Wiederholungen der \\(5\\)-fachen Kreuzvalidierung.\n\n\n\n\nDas Polynomregressionsmodell mit \\(p=2\\) stellt also ein gutes Pr√§diktionsmodell dar. Wir verwenden nun dieses Modell, um nach auff√§lligen Unterschiedenen in den herstellerseitigen Verbrauchsangaben \\(y_i\\) und unseren Pr√§diktionen zu suchen. Gerade stark negative Residuen \\(y_i-\\hat{y}_i\\) sind verd√§chtig, da es auf eine Sch√∂nung der Verbrauchsangaben hindeuten k√∂nnte.\nFolgender R-Code sch√§tzt zun√§chst das Polynomregressionsmodell mit \\(p=2\\), berechnet dann die Residuen \\(y_i-\\hat{y}_i\\) und veranschaulicht die gr√∂√üte negative Abweichung in Abbildung Figure¬†2.9.\n\np <- 2\npoly_fit <- lm(Verbrauch ~\n                   poly(Gewicht,  degree = p, raw = TRUE) +\n                   poly(PS,       degree = p, raw = TRUE) +\n                   poly(Hubraum,  degree = p, raw = TRUE),\n                 data=Auto_df)\n\n## Position des gr√∂√üten negativen Residuums:\nslct  <- order(resid(poly_fit))[1]\n## Geh√∂rt zum Mazda RX-3 (Bj. 1973)\n## Auto[slct, ]\n\npar(mar=c(5.1, 5.1, 4.1, 2.1))\nplot(y = resid(poly_fit), x = fitted(poly_fit), \n     ylab = expression(\"Residuen:\"~y[i] - hat(y)[i]), \n     xlab = expression(\"Pr√§diktionen:\"~hat(y)[i]),\n     main=\"Gr√∂√üte negative Abweichung der Verbrauchsangabe\")\npoints(y = resid(poly_fit)[slct], x = fitted(poly_fit)[slct], \n       col = \"red\", bg = \"red\", pch = 21)\ntext(y = resid(poly_fit)[slct], x = fitted(poly_fit)[slct], \n     labels = \"Mazda RX-3 (1973)\", pos = 2)\npar(mar=c(5.1, 4.1, 4.1, 2.1))\n\n\n\n\nFigure¬†2.9: Polynomregression im Anwendungsbeispiel zum Benzinverbrauch. Die gr√∂√üte negative Abweichung der Verbrauchsangabe vom zu erwartenden Verbrauch zeigt ein Mazda RX-3 von 1973.\n\n\n\n\nWir haben hier tats√§chlich einen besonderen Fall gefunden. Der Mazda RX-3 (1973) (Abbildung Figure¬†2.10) lief mit einem sehr sparsamen Wankelmotor. Dieser Motor war sogar so au√üergew√∂hnlich sparsam, dass es vielerlei Streitigkeiten um die vermeintlich zu niedrigen Verbrauchsangaben gab.\n\n\n\n\n\nFigure¬†2.10: Mazda RX-3 hatte einen Wankelmotor. Wankelmotoren waren besonders effizient und dadurch au√üergew√∂hnlich sparsam.\n\n\n\n\n\n\n\n\n\nBishop, Christopher M. 2006. Pattern Recognition and Machine Learning. Springer Science & Business Media.\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2021. An Introduction to Statistical Learning: With Applications in r. Springer Science."
  }
]