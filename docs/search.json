[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Methoden des statistischen Lernens in den Wirtschaftswissenschaften",
    "section": "",
    "text": "Tag \n    Zeit \n    Hörsaal \n  \n \n\n  \n    Dienstag \n    09:45-10:00 \n    Raum 109 \n  \n\n\n\n\n\n\n\n\n\n\nWer will, darf sich gerne im Zulip-Chat Statistisches Lernen austauschen und Fragen posten."
  },
  {
    "objectID": "01-Linear-Models-Regr_shortend.html",
    "href": "01-Linear-Models-Regr_shortend.html",
    "title": "2  Resampling Methoden zum Erlenen von Regressionsfunktionen",
    "section": "",
    "text": "Sie können …\n\ndie Probleme der Auswahl eines geeigneten Prädiktionsmodells an einem Beispiel benennen und erläutern. \ndie Grundidee der Validierungsdaten-Methode erläutern. \ndie Grundidee der k-fachen Kreuzvalidierung erläutern."
  },
  {
    "objectID": "01-Linear-Models-Regr_shortend.html#das-allgemeine-regressionsmodell",
    "href": "01-Linear-Models-Regr_shortend.html#das-allgemeine-regressionsmodell",
    "title": "2  Resampling Methoden zum Erlenen von Regressionsfunktionen",
    "section": "2.1 Das allgemeine Regressionsmodell",
    "text": "2.1 Das allgemeine Regressionsmodell\nDie einzelnen Prädiktorvariablen werden gerne kompakt zu einer multivariaten Prädiktorvariablen \\(X=(X_1,X_2,\\dots,X_p)\\) zusammengefasst; in unserem Benzinverbrauchsbeispiel also \\(X=(G,P,H,B).\\) So lässt sich das allgemeines Regressionsmodell schreiben als \\[\nY=f(X)+\\varepsilon,\n\\] wobei\n\n\\(f\\) den systematischen Zusammenhang zwischen der Zielvariable \\(Y\\) und den Prädiktorvariablen \\(X\\) beschreibt und\n\\(\\varepsilon\\) ein Fehlerterm ist, dessen bedingter Mittelwert gegeben \\(X\\) gleich null ist, \\[\nE(\\varepsilon|X)=0.\n\\]\n\nDaraus ergibt sich folgender Zusammenhang zwischen der allgemeinen Regressionsfunktion \\(f\\) und dem bedingten Mittelwert von \\(Y\\) gegeben \\(X\\): \\[\nE(Y|X)=E(f(X)+\\varepsilon|X)=f(X)\n\\] Die Funktion \\(f\\) beschreibt also den bedingten Mittelwert von \\(Y\\) gegeben \\(X\\). Ziel ist es nun, die Regressionsfunktion \\(f\\) aus den Daten zu erlernen.\n\nAbbildung Figure 2.2 zeigt ein Beispiel von \\(50\\) simulierten Daten (künstlich erzeugte Fake-Daten). Der Plot legt nahe, dass man das Einkommen mit Hilfe der Ausbildungsjahre vorhersagen kann. Normalerweise ist die wahre Funktion \\(f\\), welche die Verbindung zwischen \\(Y\\) und \\(X\\) beschreibt, unbekannt und muss aus den Daten geschätzt werden. Da es sich hier um simulierte Daten handelt, können wir den Graph der Funktion \\(f\\) als blaue Linie plotten. Einige der \\(50\\) Beobachtungspunkte \\((X,Y)\\) liegen über der Regressionsfunktion \\(f(X)\\), andere darunter. Im Großen und Ganzen haben die Fehlerterme einen Mittelwert von Null.\n\n\n\n\n\nFigure 2.2: Simulierte (künstlich erzeugte) Daten zur Veranschaulichung einer allgemeinen, univariaten Regressionsbeziehung.\n\n\n\n\nAbbildung Figure 2.3 zeigt ein simuliertes Beispiel einer allgemeinen, bivariaten Regressionsbeziehung \\[\nY=f(X)+\\varepsilon\\quad\\text{mit}\\quad X=(X_1,X_2).\n\\]\n\n\n\n\n\nFigure 2.3: Veranschaulichung einer allgemeinen, bivariaten Regressionsbeziehung.\n\n\n\n\n\n2.1.1 Der Prädiktionsfehler\n\nSei \\(\\hat{f}\\) eine Schätzung der unbekannten Regressionsfunktion \\(f,\\) geschätzt z.B. mit Hilfe der Polynomregression in Section 2.1.2. Gegeben der Schätzung \\(\\hat{f}\\) und gegeben bestimmter Prädiktorvariablen \\[\nX=(X_1,X_2,\\dots,X_p)\n\\] (z.B. Gewicht, PS und Hubraum eines neuen Autos), können wir die dazugehörige, abhängige Variable \\(Y\\) vorhersagen:\n \\[\nY\\approx \\hat{Y}=\\hat{f}(X).\n\\] \nDie Genauigkeit der Vorhersage von \\(\\hat{Y}\\) für \\(Y\\) hängt von zwei verschiedenen Prädiktionsfehlergrößen ab:\n\nReduzierbarer Prädiktionsfehler aufgrund des Schätzfehlers in \\(\\hat{f}\\). Eine genauere Schätzung kann diesen Fehler reduzieren.\nNicht reduzierbarer Prädiktionsfehler aufgrund des Fehlerterms \\(\\varepsilon\\). Das ist der Fehler, den wir selbst bei perfekter Schätzung von \\(f\\) nicht reduzieren können.\n\nDer nicht reduzierbare Fehler \\(\\varepsilon\\) enthält alle nicht messbaren und nicht gemessenen Variablen, die ebenfalls einen Einfluss auf \\(Y\\) haben. Und da wir diese Variablen nicht messen können, können wir sie auch nicht verwenden, um \\(f\\) zu schätzen.\n\nSei nun \\(\\hat{f}\\) eine gegebene Schätzung von \\(f\\) und seien \\(X\\) gegeben Werte der Prädiktorvariablen welche die Vorhersage \\(\\hat{Y}=\\hat{f}(X)\\) ergeben. Nehmen wir nun für einen Moment an, dass \\(\\hat{f}\\) und \\(X\\) gegeben und fest (also nicht zufällig) sind, dann \\[\n\\begin{align*}\nE\\left[(Y-\\hat{Y})^2\\right]\n&=E\\Big[(\\overbrace{f(X)+\\varepsilon}^{=Y} - \\overbrace{\\hat{f}(X)}^{=\\hat{Y}})^2\\Big]\\\\\n&=E\\left[\\left((f(X)-\\hat{f}(X)\\right)^2+2\\left((f(X)-\\hat{f}(X)\\right)\\varepsilon+\\varepsilon^2\\right]\\\\\n&=\\underbrace{\\left((f(X)-\\hat{f}(X)\\right)^2}_{\\text{reduzierbar}}+\\underbrace{\\operatorname{Var}(\\varepsilon)}_{\\text{nicht reduzierbar}}\n\\end{align*}\n\\]\n\nDer mittlere quadratische Prädiktionsfehler \\(E\\left[(Y-\\hat{Y})^2\\right]\\) lässt sich also in eine reduzierbare und eine nicht reduzierbare Fehlerkomponente zerlegen.\n\n\n\n\n\n\n2.1.2 Polynomregression\nDas Polynomregressionsmodell \\[\nf_p(X) = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_1^2 + \\dots + \\beta_p X_1^p  \n\\] ist eine Möglichkeit, die allgemeine Regressionsfunktion \\(f(X)=E(Y|X)\\) zu schätzen (lernen).\nDie Polynomstruktur erlaubt es, die nicht linearen Beziehungen zwischen der Zielvariablen und den Prädiktorvariablen in unserem Benzinverbrauchsproblem (siehe Abbildung Figure 2.1) zu berücksichtigen.\nSo kann, zum Beispiel, der nicht lineare Zusammenhang zwischen Verbrauch und Leistung PS sehr flexibel als Polynomfunktion modelliert werden: \\[\n\\texttt{Verbrauch}(\\texttt{PS}) = \\beta_0 + \\beta_1 \\texttt{PS} + \\beta_2 \\texttt{PS}^2 + \\dots + \\beta_p \\texttt{PS}^p\n\\] Je höher der Grad \\(p\\) des Polynoms, desto flexibler ist ein Polynomregressionsmodell.\nDas Polynomregressionsmodell ist jedoch für alle Polynomgrade \\(p\\) ein lineares Regressionsmodell, denn es ist linear bezüglich der Modellparameter \\(\\beta_0, \\beta_1, \\dots, \\beta_p\\).\nFür einen gegebenen Polynomgrad \\(p\\), lassen sich die unbekannten Modelparameter einfach mit Hilfe der Methode der kleinsten Quadrate schätzen: \\[\n\\hat{f}_p(X) = \\hat\\beta_0 + \\hat\\beta_1 X_1 + \\hat\\beta_2 X_1^2 + \\dots + \\hat\\beta_p X_1^p  \n\\] mit \\[\n\\hat\\beta = (X'X)^{-1}X'Y,\n\\]\nwobei \\[\n\\begin{align*}\n\\hat\\beta=\\left(\n  \\begin{matrix}\n  \\hat{\\beta}_0\\\\\n  \\hat{\\beta}_1\\\\\n  \\vdots\\\\\n  \\hat{\\beta}_p\n  \\end{matrix}\n\\right),\n\\quad\nX=\\left(\\begin{matrix}\n  1     &x_{11}&x_{11}^2&\\dots   & x_{11}^p\\\\\n  \\vdots&\\vdots&\\vdots  & \\ddots & \\vdots  \\\\\n  1     &x_{n1}&x_{n1}^2&\\dots   & x_{n1}^p\\\\\n  \\end{matrix}\\right)\n\\quad\n\\text{und}\n\\quad\nY=\\left(\n  \\begin{matrix}\n  y_1\\\\\n  \\vdots\\\\\n  y_n\n  \\end{matrix}\n\\right).\n\\end{align*}\n\\]\n\n## Polynom Regressionen\npolreg_1 <- lm(Verbrauch ~ poly(PS, degree = 1, raw=TRUE), data = Auto_df)\npolreg_2 <- lm(Verbrauch ~ poly(PS, degree = 2, raw=TRUE), data = Auto_df)\npolreg_5 <- lm(Verbrauch ~ poly(PS, degree = 5, raw=TRUE), data = Auto_df)\n## Data-Frame zum Abspeichern der Prädiktionen\nplot_df       <- tibble(\"PS\" = seq(45, 250, len=50))\n## Abspeichern der Prädiktionen\nplot_df$fit_1 <- predict(polreg_1, newdata = plot_df)\nplot_df$fit_2 <- predict(polreg_2, newdata = plot_df)\nplot_df$fit_5 <- predict(polreg_5, newdata = plot_df)\n## Ploten\nplot(Verbrauch ~ PS, data = Auto_df, ylim=c(2,20),\n     xlab=\"Leistung (PS)\", pch=21, col=\"gray\", bg=\"gray\", cex=1.5)\nwith(plot_df, lines(x = PS, y = fit_1, lwd=2, col=\"orange\"))\nwith(plot_df, lines(x = PS, y = fit_2, lwd=2, col=\"blue\"))\nwith(plot_df, lines(x = PS, y = fit_5, lwd=2, col=\"darkgreen\"))\nlegend(\"topright\", lty=c(NA,1,1,1), pch=c(21,NA,NA,NA), \n       col=c(\"gray\",\"orange\",\"blue\",\"darkgreen\"), pt.bg=\"gray\", pt.cex=1.5,\n       legend=c(\"Datenpunkte\", \"Grad 1\", \"Grad 2\", \"Grad 5\"), bty=\"n\")\n\n\n\n\nPolynom Regression bei verschiedenen Polynomgraden \\(p\\).\n\n\n\n\n\n2.1.2.1 Überanpassung\nZusätzlich zur Wahl der Modellparameter \\(\\hat{\\beta}_0, \\hat{\\beta}_1, \\dots, \\hat{\\beta}_p\\) besteht hier nun das Problem der Wahl des Grades \\(p\\) des Polynoms als weiteren Modellparameter \\[\ny_i=\\hat{\\beta}_0 + \\hat{\\beta}_1 x_{i1} + \\hat{\\beta}_2 x_{i2}^2 + \\dots + \\hat{\\beta}_p x_{ip}^p + e_i\n\\] Wenn man jedoch versucht, alle Modellparameter (also \\(\\hat{\\beta}_0, \\hat{\\beta}_1, \\dots, \\hat{\\beta}_p\\) und \\(p\\)) durch Minimieren der Trainingsdaten-RSS \\[\n\\operatorname{RSS}\\equiv\\operatorname{RSS}(\\hat{\\beta}_0, \\hat{\\beta}_1, \\dots, \\hat{\\beta}_p,p)=e_1^2 + e_2^2 + \\dots + e_n^2\n\\] zu schätzen, so ergibt sich ein Problem das als Überanpassung (Overfitting) bekannt ist (siehe Abbildung Figure 2.4). Das Polynomregressionsmodell ist so flexibel, dass es den einzelnen Trainingsdaten \\((x_i,y_i)\\) folgen kann. Eine Überangepassung an die Trainingsdaten führt jedoch notwendigerweise zu einer Verschlechterung der Vorhersagegüte bezüglich neuer Daten.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.4: Polynom Regression und die Wahl des Polynomgrades \\(p\\) durch Minimierung der Trainingsdaten-RSS. (Eine schlechte Idee).\n\n\n\n\n\n\nProblem der Methode der kleinsten Quadrate\n\nDas Minimieren der Residuen-Quadratsumme (Residual Sum of Squares, RSS) is äquivalent zum minimieren des mittleren quadratischen Fehlers bzgl. der Trainingsdaten \\[\n\\frac{1}{n}\\operatorname{RSS}_p=\\frac{1}{n}\\sum_{i=1}^n\\left(y_i - \\hat{f}_p(x_i)\\right)^2,\n\\] wobei \\((y_i,x_i),\\) \\(i=1,\\dots,n\\) hier die beobachteten Trainingsdaten bezeichnet.\nFür hohe Polynomgrade \\(p\\) wird \\(\\hat{f}_p(x_i)\\) sehr flexibel, sodass \\[\ny_i \\approx \\hat{f}_p(x_i).\n\\] Dies erklärt die Beobachtung, dass \\(\\operatorname{RSS}_p\\) monoton fallend ist in \\(p,\\) also \\[\n\\operatorname{RSS}_p\\geq \\operatorname{RSS}_{p'}\\quad\\text{für}\\quad p < p'.\n\\]\n\nDamit erlernt \\(\\hat{f}_p(x_i)\\) von \\(y_i\\)\n\nden erwünschten Teil \\(f(x_i)\\)\naber auch den unerwünschten Fehlerterm \\(\\varepsilon_i\\) 😭\n\nDas erlernte Model \\(\\hat{f}_p(x_i)\\) ist fehlerbehaftet, d.h. \\(\\hat{f}_p(x_i)\\not\\approx f(x_i).\\)\n\n\n\nMittlerer quadratischer Fehlers bzgl. der Testdaten\nUm eine Überanpassung an die Trainingsdaten zu verhindern, müss man die Prädiktionsgüte von \\(\\hat{f}_p(x_i)\\) mit Hilfe neuer Testdaten überprüfen.\nEine häufig betrachtete Größe ist der mittlere quadrierte Prädiktionsfehler (mean squared prediction error, MSPE) \\[\n\\operatorname{MSPE}_{Test}=\\frac{1}{m}\\sum_{i=1}^m\\left(y^{Test}_i - \\hat{f}_p(x^{Test}_i)\\right)^2,\n\\] wobei\n\n\\((y^{Test}_i,x^{Test}_i),\\) \\(i=1,\\dots,m\\) die Testdaten bezeichnet,\n\\(\\hat{f}_p\\) jedoch auf Basis der Trainingsdaten berechnet wurde.\n\nDie Trainings- und Testdaten müssen voneinander unabhängig sein, sodass \\[\n\\begin{align*}\n&\\operatorname{MSPE}^{Test}_p\n=\\frac{1}{m}\\sum_{i=1}^m\\left(y^{Test}_i - \\hat{f}_p(x^{Test}_i)\\right)^2\\\\\n&=\\frac{1}{m}\\sum_{i=1}^m\\left((f(x^{Test}_i)+\\varepsilon^{Test}_i) - \\hat{f}_p(x^{Test}_i)\\right)^2\\\\\n&=\\underbrace{\\frac{1}{m}\\sum_{i=1}^m\\left(f(x^{Test}_i)-\\hat{f}_p(x^{Test}_i)\\right)^2}_{\\approx E\\left(\\left(f(X)-\\hat{f}_p(X)\\right)^2\\right)}\n+\\underbrace{\\frac{1}{m}\\sum_{i=1}^m\\left(\\varepsilon_i^{Test}\\right)^2}_{\\approx \\operatorname{Var}(\\varepsilon)}\n-\\underbrace{\\frac{1}{m}\\sum_{i=1}^m\\varepsilon_i^{Test}\\hat{f}_p(x^{Test}_i)}_{\\approx 0}\n\\end{align*}\n\\]\nDie Minimierung von \\(\\operatorname{MSPE}^{Test}_p\\) bzgl \\(p\\) entspricht also (approximativ for große \\(m\\)) einer Minimierung von \\[\nE\\left(\\left(f(X)-\\hat{f}_p(X)\\right)^2\\right).\n\\]\n\\(\\operatorname{MSPE}^{Test}_p\\) stellt damit ein korrigiertes kleinste Quadrate Kriterium dar, welches eine Anpassung an die Fehlerterm \\(\\varepsilon_i\\) verhindert."
  },
  {
    "objectID": "01-Linear-Models-Regr_shortend.html#resampling-methoden-zur-modellauswahl",
    "href": "01-Linear-Models-Regr_shortend.html#resampling-methoden-zur-modellauswahl",
    "title": "2  Resampling Methoden zum Erlenen von Regressionsfunktionen",
    "section": "2.2 Resampling Methoden zur Modellauswahl",
    "text": "2.2 Resampling Methoden zur Modellauswahl\n\nMaschinelles Lernen versus Strukturelle Modelle\n\n\n\n\n\n2.2.1 Die Validierungsdaten-Methode\nDa die Minimierung der Trainingsdaten-RSS schnell zu einem Problem der Überanpassung führt, benötigen wir eine alternative Methode, um die Güte des geschätzten Modells zu prüfen. Die einfachste Idee ist dabei die beobachteten Daten \\[\n(x_i,y_i),\\quad i\\in\\mathcal{I}=\\{1,2,\\dots,n\\}\n\\] in einen Satz von Trainingsdaten \\[\n\\left\\{(x_{1}^{Train},y_{1}^{Train}),\\dots,(x_{n_{Train}}^{Train},y_{n_{Train}}^{Train})\\right\\}=\\{(x_i,y_i):i\\in\\mathcal{I}^{Train}\\}\n\\] und einen separaten (disjunkten) Satz von Validierungsdaten \\[\n\\left\\{(x_{1}^{Valid},y_{1}^{Valid}), \\dots,(x_{n_{Valid}}^{Valid},y_{n_{Valid}}^{Valid})\\right\\}=\\{(x_i,y_i):i\\in\\mathcal{I}^{Valid}\\}\n\\] zu teilen mit \\[\n\\overbrace{|\\mathcal{I}|}^{=n}=\\overbrace{|\\mathcal{I}^{Train}|}^{=n_{Train}}+\\overbrace{|\\mathcal{I}^{Valid}|}^{=n_{Valid}},\n\\] sodass \\(\\mathcal{I}^{Train}\\cap\\mathcal{I}^{Valid} = \\emptyset\\)\nFolgender Code-Schnipsel ermöglicht solch eine (zufällige) Aufteilung der Daten in Trainings- und Validierungsdaten:\n\nn        <- nrow(Auto_df) # Stichprobenumfang\nn_Train  <- 200           # Stichprobenumfang der Trainingsdaten\nn_Valid  <- n - n_Train   # Stichprobenumfang der Validierungsdaten\n\n## Index-Mengen zur Auswahl der \n## Trainings- und Validierungsdaten\nI_Train  <- sample(x = 1:n, size = n_Train, replace = FALSE)\nI_Valid  <- c(1:n)[-I_Train]\n\n## Trainingsdaten \nAuto_Train_df <- Auto_df[I_Train, ]\n## Validierungsdaten \nAuto_Valid_df <- Auto_df[I_Valid, ]\n\nObschon die Validierungsdaten-Methode auf alle Regressionsmodelle angewandt werden kann, veranschaulichen wir im Folgenden die Methode anhand der Polynomregression.\nDie Aufteilung der Daten in Trainings- und Validierungsdaten ermöglicht uns nun ein zweistufiges Verfahren:\nSchritt 1: Mit Hilfe der Trainingsdaten wird das Polynomregressionsmodell geschätzt: \\[\n\\begin{align*}\ny^{Train}_i\n%&=\\hat{f}^{Train}_p(x_i^{Train}) + e_i^{Train}\\\\\n&=\\hat{\\beta}_0^{Train} + \\hat{\\beta}_1^{Train} x_{i}^{Train} + \\hat{\\beta}_2^{Train} (x_{i}^{Train})^2 + \\dots + \\hat{\\beta}_p^{Train} (x_{i}^{Train})^p + e_i^{Train}\n\\end{align*}\n\\] Code-Schnipsel Beispiel:\n\nTrain_polreg <- lm(Verbrauch ~ poly(PS, degree = p, raw=TRUE), data = Auto_Train_df)\n\nSchritt 2: Mit Hilfe der Validierungsdaten wird das geschätzte Polynomregressionsmodell validiert: \\[\n\\begin{align*}\n\\hat{y}^{Valid}_i\n%&=\\hat{f}_p^{Train}(x_i^{Valid})+ e_i^{Valid}\\\\\n&=\\hat{\\beta}_0 + \\hat{\\beta}_1^{Train} x_{i}^{Valid} + \\hat{\\beta}_2^{Train} (x_{i}^{Valid})^2 + \\dots + \\hat{\\beta}_p^{Train} (x_{i}^{Valid})^p,\n\\end{align*}\n\\] indem man den mittleren quadratischen Prädiktionsfehler (Mean Squared Prediction Error MSPE) berechnet: \\[\n\\begin{align*}\n\\text{MSPE}\n&=\\frac{1}{n_{Valid}}\\text{RSS}_{Valid}\\\\\n&=\\frac{1}{n_{Valid}}\\left((y_1^{Valid} - \\hat{y}_1^{Valid})^2 +\\dots + (y_{n_{Valid}}^{Valid} - \\hat{y}_{n_{Valid}}^{Valid})^2\\right)\n\\end{align*}\n\\] Code-Schnipsel Beispiel:\n\ny_fit_Valid   <- predict(Train_polreg, newdata = Auto_Valid_df)\nRSS_Valid     <- sum( (Auto_Valid_df$Verbrauch - y_fit_Valid)^2 )\nMSPE          <- RSS_Valid / n_Valid\n\nMan wiederholt obige Schritte für eine Auswahl von verschiedenen Polynomgraden \\(p=1,2,\\dots,p_{\\max}\\), z.B. \\(p_{\\max}=10\\), und berechnet für jeden dieser Fälle den \\(\\operatorname{MSPE}\\), also: \\[\n\\operatorname{MSPE}\\equiv\\operatorname{MSPE}(\\hat{\\beta}_0, \\hat{\\beta}_1, \\dots, \\hat{\\beta}_p,p),\\quad\\text{für jedes}\\quad p=1,2,\\dots,p_{\\max}\n\\] Der \\(\\operatorname{MSPE}\\) ist eine Schätzung des wahren, unbekannten mittleren quadratischen Prädiktionsfehlers \\(E\\left[(Y-\\hat{Y})^2\\right]\\),\n\\[\n\\operatorname{MSPE}(\\hat{\\beta}_0, \\hat{\\beta}_1, \\dots, \\hat{\\beta}_p,p)\\approx E\\left[(Y-\\hat{Y})^2\\right].\n\\] Die Minimierung des \\(\\operatorname{MSPE}\\) über verschiedene Werte des Polynomgrades \\(p=1,2,\\dots\\) erlaubt es uns den reduzierbaren Prädiktions-Fehler der Polynomregression zu minimieren.\nFolgender R-Code verbindet nun alle Schritte und berechnet den \\(\\operatorname{MSPE}\\) für verschiedene Werte des Polynomgrades \\(p\\). Dasjenige Modell, welches den \\(\\operatorname{MSPE}\\) minimiert, ist laut der Daten das beste Prädiktionsmodell.\n\nset.seed(31)\n##\nn        <- nrow(Auto_df) # Stichprobenumfang\nn_Train  <- 200           # Stichprobenumfang der Trainingsdaten\nn_Valid  <-n - n_Train    # Stichprobenumfang der Validierungsdaten\n\n## Index-Mengen zur Auswahl der \n## Trainings- und Validierungsdaten\nI_Train  <- sample(x = 1:n, size = n_Train, replace = FALSE)\nI_Valid  <- c(1:n)[-I_Train]\n\n## Trainingsdaten \nAuto_Train_df <- Auto_df[I_Train, ]\n## Validierungsdaten \nAuto_Valid_df <- Auto_df[I_Valid, ]\n\np_max         <- 6\nMSPE          <- numeric(p_max)\nfit_plot      <- matrix(NA, 50, p_max)\nfor(p in 1:p_max){\n  ## Schritt 1\n  Train_polreg <- lm(Verbrauch ~ poly(PS, degree = p, raw=TRUE), \n                     data = Auto_Train_df)\n  ## Schritt 2\n  y_fit_Valid   <- predict(Train_polreg, newdata = Auto_Valid_df)\n  RSS_Valid     <- sum( (Auto_Valid_df$Verbrauch - y_fit_Valid)^2 )\n  MSPE[p]       <- RSS_Valid / n_Valid\n  ## Daten für's plotten\n  fit_plot[,p] <- predict(Train_polreg, newdata = plot_df)\n}\n\n\n\n\n\n\nPolynom Regression und die Wahl des Polynomgrades \\(p\\) durch Minimierung des mittleren quadratischen Prädiktionsfehler MSPE.\n\n\n\n\n\nAchtung: Auch eine Modellauswahl ist fehlerhaft und stellt lediglich eine Schätzung (mit Schätzfehlern) des besten Prädiktionsmodelles innerhalb der betrachteten Klasse von Prädiktionsmodellen (hier Polynomregressionen) dar.\n\nAbbildung Figure 2.5 zeigt jedoch ein Problem der Validierungsdaten-Methode. Die Trainingsdaten und die Validierungsdaten haben kleinere Stichprobenumfänge (\\(n_{Train}<n\\) und \\(n_{Valid}<n\\)) was zu einer erhöhten Schätzgenauigkeit in der MSPE-Schätzung führt.\n\n\n\n\n\nFigure 2.5: Zehn verschiedene MSPE-Berechnungen basierend auf zehn verschiedenen, zufälligen Aufteilungen der Daten in Trainings- und Validierungsdaten.\n\n\n\n\n\n\n2.2.2 k-Fache Kreuzvalidierung\nDie \\(k\\)-fache (z.B. \\(k=5\\) oder \\(k=10\\)) Kreuzvalidierung ist eine Vorgehensweise zur Bewertung der Leistung einer Schätzprozedur (Algorithmus) im Kontext des maschinellen Lernens. Als Schätzprozedur verwenden wir wieder das Beispiel der Polynomregression mit unbekanntem Polynomgrad \\(p\\), welcher zusammen mit den Modellparametern \\(\\beta_0,\\beta_1,\\dots,\\beta_p\\) aus den Daten erlernt werden muss.\nDie \\(k\\)-fache Kreuzvalidierung stellt eine Verbesserung der Validierungsdaten-Methode dar, da sie faktisch die Stichprobenumfänge in den Trainingsdaten und Validierungsdaten erhöht. Wie bei der Validierungsdaten-Methode wird der Datensatz in Trainings- und Validierungsdaten aufgeteilt – jedoch \\(k\\)-fach. Abbildung Figure 2.6 zeigt ein Beispiel der Datenaufteilung bei der \\(5\\)-fachen Kreuzvalidierung.\n\n\n\n\n\nFigure 2.6: Datenaufteilung in Trainings- und Validierungsdaten bei der \\(5\\)-fachen Kreuzvalidierung.\n\n\n\n\n\nFolgender Code-Schnipsel ermöglicht eine (zufällige) Aufteilung der Daten in \\(k\\) verschiedene Trainings- und Validierungsdaten:\n\nn      <- nrow(Auto_df) # Stichprobenumfang\nk      <- 5             # 5-fache Kreuzvalidierung\n\n## Index zur Auswahl k verschiedener  \n## Trainings- und Validierungsdaten:\nfolds  <- sample(x = 1:k, size = n, replace=TRUE)\n\n## Trainingsdaten im j-ten (j=1,2,...,k) Durchgang\nAuto_df[folds != j,]\n## Validierungsdaten im j-ten (j=1,2,...,k) Durchgang\nAuto_df[folds == j,]\n\n\nFür jede der \\(k\\) Datenaufteilungen wird der \\(\\operatorname{MSPE}\\) berechnet. Der Mittelwert dieser MSPE-Werte wird häufig als \\(\\operatorname{CV}_{(k)}\\) Wert (crossvalidation score) bezeichnet \\[\n\\operatorname{CV}_{(k)}=\\frac{1}{k}\\sum_{j=1}^k\\operatorname{MSPE}_j\n\\]\nDer \\(\\operatorname{CV}_{(k)}\\)-Wert stellt eine im Vergleich zur Validierungsdaten-Methode verbesserte Schätzung des unbekannten mittleren quadratischen Pädiktionsfehlers \\(\\operatorname{CV}_{(k)}\\approx E[(Y-\\hat{Y})^2]\\) dar. Die Modellauswahl folgt also auch hier mittels Minimierung des \\(\\operatorname{CV}_{(k)}\\)-Wertes über die verschiedene Werte des Polynomgrades \\(p=1,2,\\dots\\).\n\nWahl von \\(k\\): In der Praxis haben sich die Werte \\(k=5\\) und \\(k=10\\) etabliert, da diese Größenordnunen einen guten Kompromiss zwischen der Varianz und der Verzerrung des Schätzers \\(\\operatorname{CV}_{(k)}\\) für \\(E[(Y-\\hat{Y})^2]\\) darstellen."
  },
  {
    "objectID": "01-Linear-Models-Regr_shortend.html#anwendung-vorhersage-des-benzinverbrauchs-fraud-detection",
    "href": "01-Linear-Models-Regr_shortend.html#anwendung-vorhersage-des-benzinverbrauchs-fraud-detection",
    "title": "2  Resampling Methoden zum Erlenen von Regressionsfunktionen",
    "section": "2.3 Anwendung: Vorhersage des Benzinverbrauchs (Fraud Detection)",
    "text": "2.3 Anwendung: Vorhersage des Benzinverbrauchs (Fraud Detection)\n\n\n\n\n\nFigure 2.7: Hauptursache für die hohe, gesundheitsgefährdende NO2-Belastung der Stadtluft sind Diesel-Fahrzeuge (Foto von David Lee).\n\n\n\n\nNun haben wir das Werkzeug, um die nicht linearen Zusammenhänge zwischen der Zielvariable \\(Y=\\)Verbrauch und den Prädiktorvariablen \\(G=\\)Gewicht, \\(P=\\)PS und \\(H=\\)Hubraum im Datensatz Auto_df zu berücksichtigen (siehe Abbildung Figure 2.1) und allein mit Hilfe der Daten zu erlernen. Wir folgen hier der Herangehensweise des maschinellen Lernens und lassen die Daten für sich selbst sprechen.\nDa Abbildung Figure 2.1 sehr ähnliche Zusammenhänge zwischen der Zielvariable \\(Y=\\)Verbrauch und den Prädiktorvariablen \\(G=\\)Gewicht, \\(P=\\)PS und \\(H=\\)Hubraum vermuten lässt, betrachten wir zunächst ein vereinfachtest Polynomregressionsmodell, bei dem für alle Prädiktorvariablen der gleiche Polynomgrad \\(p\\) verwendet wird.\n\\[\n\\begin{align*}\nY_i = \\beta_0 + \\notag\n& \\beta^G_{1} G_i + \\beta^G_{2} G_i^2 + \\dots + \\beta^G_{p} G_i^p + \\\\\n& \\beta^P_{1} P_i + \\beta^P_{2} P_i^2 + \\dots + \\beta^P_{p} P_i^p +  \\\\\n& \\beta^H_{1} H_i + \\beta^H_{2} H_i^2 + \\dots + \\beta^H_{p} H_i^p +  \\varepsilon_i\n\\end{align*}\n\\]\nFolgender R-Code (Algorithmus) erlernt aus den Daten, mit Hilfe der \\(5\\)-fachen Kreuzvalidierung \\(\\operatorname{CV}_{(5)}\\approx E[(Y-\\hat{Y})^2]\\), den optimalen Polynomgrad \\(p\\).\n\nset.seed(8)             # Seed für den Zufallsgenerator\n\nn      <- nrow(Auto_df) # Stichprobenumfang\nk      <- 5             # 5-fache Kreuzvalidierung\np_max  <- 5             # Maximaler Polynomgrad\n\nfolds     <- sample(x = 1:k, size = n, replace=TRUE)\n\n## Container für die MSPE-Werte \n## für alle j=1,...,k Kreuzvalidierungen und \n## für alle p=1,...,p_max Polynomgrade\nMSPE <- matrix(NA, nrow = k, ncol = p_max,\n                    dimnames=list(NULL, paste0(\"p=\",1:p_max)))\n\nfor(p in 1:p_max){\n  for(j in 1:k){\n  ## Modelschätzung auf Basis j-ten Traininsdaten Auto_df[folds != j,]\n  poly_fit <- lm(Verbrauch ~\n                   poly(Gewicht,        degree = p, raw = TRUE) +\n                   poly(PS,             degree = p, raw = TRUE) +\n                   poly(Hubraum,        degree = p, raw = TRUE),\n                 data=Auto_df[folds != j,])\n    ## Prädiktion  auf Basis j-ten Validierungsdaten Auto_df[folds == j,]\n    pred          <- predict(poly_fit, newdata = Auto_df[folds == j,])\n    ## \n    MSPE[j,p] <- mean( (Auto_df$Verbrauch[folds==j] - pred)^2 )\n  }\n}\n\n## CV-Wert für alle p=1,...,p_max Polynomgrade \nCV_k <- colMeans(MSPE)\n\n## Plotten\nplot(y = CV_k, x = 1:length(CV_k), pch=21, col=\"black\", bg=\"black\", \n     type='b', xlab=\"Polynomgrad p\", ylab=expression(CV[(5)]), log=\"y\")\npoints(y = CV_k[which.min(CV_k)],\n       x = c(1:length(CV_k))[which.min(CV_k)],\n       col = \"red\", bg = \"red\", pch = 21)\n\n\n\n\nAuch der \\(5\\)-fache Kreuzvalidierungswert \\(\\operatorname{CV}_{(5)}\\) ist lediglich eine zufallsbehaftete Schätzung des unbekannten mittleren quadratischen Prädiktionsfehlers \\(E[(Y-\\hat{Y})^2]\\). Um eine Idee von der Präzision und Stabilität der Modellauswahl mittels der Minimierung von \\(\\operatorname{CV}_{(5)}\\) zu bekommen, können wir die zufälligen, \\(5\\)-fachen Aufteilungen der Daten in Trainins- und Validierungsdaten wiederholen und den Effekt alternativer Datenaufteilungen betrachten. Abbildung Figure 2.8 zeigt, dass die Minimierung des Kreuzvalidierungswertes \\(\\operatorname{CV}_{(5)}\\) auch in Wiederholungen häufig das Modell mit Polynomgrad \\(p=2\\) auswählt. Der Polynomgrad \\(p=2\\) scheint also eine vertauenswürde Modellauswahl darzustellen.\n\n\n\n\n\nFigure 2.8: Zehn verschiedene \\(\\operatorname{CV}_{(k)}\\)-Berechnungen basierend auf zehn verschiedenen, zufälligen Wiederholungen der \\(5\\)-fachen Kreuzvalidierung.\n\n\n\n\nDas Polynomregressionsmodell mit \\(p=2\\) stellt also ein gutes Prädiktionsmodell dar. Wir verwenden nun dieses Modell, um nach auffälligen Unterschiedenen in den herstellerseitigen Verbrauchsangaben \\(y_i\\) und unseren Prädiktionen zu suchen. Gerade stark negative Residuen \\(y_i-\\hat{y}_i\\) sind verdächtig, da es auf eine Schönung der Verbrauchsangaben hindeuten könnte.\nFolgender R-Code schätzt zunächst das Polynomregressionsmodell mit \\(p=2\\), berechnet dann die Residuen \\(y_i-\\hat{y}_i\\) und veranschaulicht die größte negative Abweichung in Abbildung Figure 2.9.\n\np <- 2\npoly_fit <- lm(Verbrauch ~\n                   poly(Gewicht,  degree = p, raw = TRUE) +\n                   poly(PS,       degree = p, raw = TRUE) +\n                   poly(Hubraum,  degree = p, raw = TRUE),\n                 data=Auto_df)\n\n## Position des größten negativen Residuums:\nslct  <- order(resid(poly_fit))[1]\n## Gehört zum Mazda RX-3 (Bj. 1973)\n## Auto[slct, ]\n\npar(mar=c(5.1, 5.1, 4.1, 2.1))\nplot(y = resid(poly_fit), x = fitted(poly_fit), \n     ylab = expression(\"Residuen:\"~y[i] - hat(y)[i]), \n     xlab = expression(\"Prädiktionen:\"~hat(y)[i]),\n     main=\"Größte negative Abweichung der Verbrauchsangabe\")\npoints(y = resid(poly_fit)[slct], x = fitted(poly_fit)[slct], \n       col = \"red\", bg = \"red\", pch = 21)\ntext(y = resid(poly_fit)[slct], x = fitted(poly_fit)[slct], \n     labels = \"Mazda RX-3 (1973)\", pos = 2)\npar(mar=c(5.1, 4.1, 4.1, 2.1))\n\n\n\n\nFigure 2.9: Polynomregression im Anwendungsbeispiel zum Benzinverbrauch. Die größte negative Abweichung der Verbrauchsangabe vom zu erwartenden Verbrauch zeigt ein Mazda RX-3 von 1973.\n\n\n\n\nWir haben hier tatsächlich einen besonderen Fall gefunden. Der Mazda RX-3 (1973) (Abbildung Figure 2.10) lief mit einem sehr sparsamen Wankelmotor. Dieser Motor war sogar so außergewöhnlich sparsam, dass es vielerlei Streitigkeiten um die vermeintlich zu niedrigen Verbrauchsangaben gab.\n\n\n\n\n\nFigure 2.10: Mazda RX-3 hatte einen Wankelmotor. Wankelmotoren waren besonders effizient und dadurch außergewöhnlich sparsam.\n\n\n\n\n\n\n\n\n\nBishop, Christopher M. 2006. Pattern Recognition and Machine Learning. Springer Science & Business Media.\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2021. An Introduction to Statistical Learning: With Applications in r. Springer Science."
  }
]