<!DOCTYPE html>
<html lang="de" xml:lang="de">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>1 Der Expectation Maximization (EM) Algorithmus | Computational Statistics</title>
  <meta name="description" content="1 Der Expectation Maximization (EM) Algorithmus | Computational Statistics" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="1 Der Expectation Maximization (EM) Algorithmus | Computational Statistics" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="/images/Florence_Nightingale.jpg" />
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="1 Der Expectation Maximization (EM) Algorithmus | Computational Statistics" />
  
  
  <meta name="twitter:image" content="/images/Florence_Nightingale.jpg" />

<meta name="author" content="Prof. Dr. Dominik Liebl" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="1.1-motivation-clusteranalyse-mit-hilfe-gaußscher-mischverteilungen.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
<link rel="stylesheet" href="toc.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><center><a href="http://www.dliebl.com/Computational_Statistics_Script/"><img src="images/Florence_Nightingale.jpg" alt="logo" width="60%" height="60%"style="margin: 15px 0 0 0"></a></center></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Informationen</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#vorlesungszeiten"><i class="fa fa-check"></i>Vorlesungszeiten</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#rcodes"><i class="fa fa-check"></i>RCodes</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#leseecke"><i class="fa fa-check"></i>Leseecke</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#florence-nightingale"><i class="fa fa-check"></i>Florence Nightingale</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="1-der-expectation-maximization-em-algorithmus.html"><a href="1-der-expectation-maximization-em-algorithmus.html"><i class="fa fa-check"></i><b>1</b> Der Expectation Maximization (EM) Algorithmus</a>
<ul>
<li class="chapter" data-level="" data-path="1-der-expectation-maximization-em-algorithmus.html"><a href="1-der-expectation-maximization-em-algorithmus.html#lernziele-für-dieses-kapitel"><i class="fa fa-check"></i>Lernziele für dieses Kapitel</a></li>
<li class="chapter" data-level="" data-path="1-der-expectation-maximization-em-algorithmus.html"><a href="1-der-expectation-maximization-em-algorithmus.html#begleitlektüren"><i class="fa fa-check"></i>Begleitlektüre(n)</a></li>
<li class="chapter" data-level="" data-path="1-der-expectation-maximization-em-algorithmus.html"><a href="1-der-expectation-maximization-em-algorithmus.html#r-pakete-für-diese-kapitel"><i class="fa fa-check"></i>R-Pakete für diese Kapitel</a></li>
<li class="chapter" data-level="1.1" data-path="1.1-motivation-clusteranalyse-mit-hilfe-gaußscher-mischverteilungen.html"><a href="1.1-motivation-clusteranalyse-mit-hilfe-gaußscher-mischverteilungen.html"><i class="fa fa-check"></i><b>1.1</b> Motivation: Clusteranalyse mit Hilfe Gaußscher Mischverteilungen</a></li>
<li class="chapter" data-level="1.2" data-path="1.2-der-em-algorithmus-zur-ml-schätzung-gaußscher-mischverteilungen.html"><a href="1.2-der-em-algorithmus-zur-ml-schätzung-gaußscher-mischverteilungen.html"><i class="fa fa-check"></i><b>1.2</b> Der EM Algorithmus zur ML-Schätzung Gaußscher Mischverteilungen</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="1.2-der-em-algorithmus-zur-ml-schätzung-gaußscher-mischverteilungen.html"><a href="1.2-der-em-algorithmus-zur-ml-schätzung-gaußscher-mischverteilungen.html#gaußsche-mischmodelle-gmm"><i class="fa fa-check"></i><b>1.2.1</b> Gaußsche Mischmodelle (GMM)</a></li>
<li class="chapter" data-level="1.2.2" data-path="1.2-der-em-algorithmus-zur-ml-schätzung-gaußscher-mischverteilungen.html"><a href="1.2-der-em-algorithmus-zur-ml-schätzung-gaußscher-mischverteilungen.html#maximum-likelihood-ml-schätzung"><i class="fa fa-check"></i><b>1.2.2</b> Maximum Likelihood (ML) Schätzung</a></li>
<li class="chapter" data-level="1.2.3" data-path="1.2-der-em-algorithmus-zur-ml-schätzung-gaußscher-mischverteilungen.html"><a href="1.2-der-em-algorithmus-zur-ml-schätzung-gaußscher-mischverteilungen.html#ch:EM1"><i class="fa fa-check"></i><b>1.2.3</b> Der EM Algorithmus für GMMs</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="1.3-der-alternative-wahre-blick-auf-den-em-algorithmus.html"><a href="1.3-der-alternative-wahre-blick-auf-den-em-algorithmus.html"><i class="fa fa-check"></i><b>1.3</b> Der alternative (wahre) Blick auf den EM Algorithmus</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="1.3-der-alternative-wahre-blick-auf-den-em-algorithmus.html"><a href="1.3-der-alternative-wahre-blick-auf-den-em-algorithmus.html#vervollständigung-der-daten"><i class="fa fa-check"></i><b>1.3.1</b> Vervollständigung der Daten</a></li>
<li class="chapter" data-level="1.3.2" data-path="1.3-der-alternative-wahre-blick-auf-den-em-algorithmus.html"><a href="1.3-der-alternative-wahre-blick-auf-den-em-algorithmus.html#a-priori-und-a-posteriori-wahrscheinlichkeiten-pi_g-und-p_ig"><i class="fa fa-check"></i><b>1.3.2</b> A-priori und A-posteriori Wahrscheinlichkeiten: <span class="math inline">\(\pi_g\)</span> und <span class="math inline">\(p_{ig}\)</span></a></li>
<li class="chapter" data-level="1.3.3" data-path="1.3-der-alternative-wahre-blick-auf-den-em-algorithmus.html"><a href="1.3-der-alternative-wahre-blick-auf-den-em-algorithmus.html#der-bedingte-mittelwert-p_ig"><i class="fa fa-check"></i><b>1.3.3</b> Der (bedingte) Mittelwert: <span class="math inline">\(p_{ig}\)</span></a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="1.4-das-große-ganze.html"><a href="1.4-das-große-ganze.html"><i class="fa fa-check"></i><b>1.4</b> Das Große Ganze</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="1.4-das-große-ganze.html"><a href="1.4-das-große-ganze.html#ch:EM2"><i class="fa fa-check"></i><b>1.4.1</b> Der EM Algorithmus: <em>Die abstrakte Version</em></a></li>
<li class="chapter" data-level="" data-path="1.4-das-große-ganze.html"><a href="1.4-das-große-ganze.html#ende"><i class="fa fa-check"></i>Ende</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="2-lineare-regressionsmodelle.html"><a href="2-lineare-regressionsmodelle.html"><i class="fa fa-check"></i><b>2</b> Lineare Regressionsmodelle</a>
<ul>
<li class="chapter" data-level="" data-path="2-lineare-regressionsmodelle.html"><a href="2-lineare-regressionsmodelle.html#begleitlektüren-1"><i class="fa fa-check"></i>Begleitlektüre(n)</a></li>
<li class="chapter" data-level="2.1" data-path="2.1-einführung.html"><a href="2.1-einführung.html"><i class="fa fa-check"></i><b>2.1</b> Einführung</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="literatur.html"><a href="literatur.html"><i class="fa fa-check"></i>Literatur</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Computational Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="der-expectation-maximization-em-algorithmus" class="section level1" number="1">
<h1><span class="header-section-number">1</span> Der Expectation Maximization (EM) Algorithmus</h1>
<style type="text/css">
span {
  display: inline-block;
}
</style>
<p>Der EM Algorithmus wird häufig verwendet, um komplizierte Maximum Likelihood Schätzprobleme zu vereinfachen bzw. überhaupt erst möglich zu machen. In diesem Kapitel stellen wir den EM Algorithmus zur Schätzung von Gaußschen Mischverteilungen vor, da der EM Algorithmus hier wohl seine bekannteste Anwendung hat. Bereits die originale Arbeit zum EM Algorithmus <span class="citation">(<a href="#ref-Dempster_1977" role="doc-biblioref">Dempster, Laird, und Rubin 1977</a>)</span> beschäftigt sich mit der Schätzung von Gaußschen Mischverteilungen.</p>
<p><strong>Mögliche Anwendungen von Gaußschen Mischverteilungen:</strong></p>
<ul>
<li><p>Generell: Auffinden von Gruppierungen (zwei oder mehr) in den Daten (<strong>Clusteranalyse</strong>). Zum Beispiel:</p>
<ul>
<li>Automatisierte Videobearbeitungen (z.B. Bildeinteilungen in Vorder- und Hintergrund)</li>
<li>Automatisierte Erkennung von Laufstilen</li>
<li>etc.</li>
</ul></li>
</ul>
<!-- [@Liebl2014] -->
<!-- **Zur Info:** Gaußsche Mischverteilungen werden häufig in der Clusteranalyse verwendet. Da einem GMM ein Wahrscheinlichkeitsmodell zu Grunde liegt, gehören GMM-basierte Clustermethoden zu den *modellbasierten Clusterverfahren*. Das wohl beste und bekannteste R-Paket zur Schätzung und Verwendung von Gaußschen Mischungsmodellen ist das <tt>mclust</tt> package [@mclust]. -->
<div id="lernziele-für-dieses-kapitel" class="section level3 unnumbered">
<h3>Lernziele für dieses Kapitel</h3>
<p>Sie können …</p>
<ul>
<li>ein <strong>Anwendungsfeld</strong> des EM Algorithmuses <strong>benennen</strong>.
<br></li>
<li>die <strong>Probleme</strong> der klassischen Maximum Likelihood Methode zur Schätzung von Gaußschen Mischverteilungen <strong>benennen und erläutern</strong>.
<br></li>
<li>die <strong>Grundidee</strong> des EM Algorithmuses <strong>erläutern</strong>.
<br></li>
<li>den <strong>EM Algorithmus</strong> zur Schätzung von Gaußschen Mischverteilungen <strong>anwenden</strong>.
<br></li>
<li>die <strong>Grundidee</strong> der Vervollständigung der Daten durch latente Variablen <strong>erläutern</strong>.
<br></li>
</ul>
</div>
<div id="begleitlektüren" class="section level3 unnumbered">
<h3>Begleitlektüre(n)</h3>
<p>Zur Vorbereitung der Klausur ist es grundsätzlich aussreichend dieses Kapitel durchzuarbeiten - aber Lesen hat ja noch nie geschadet. Dieses Kapitel basiert hauptsächlich auf:</p>
<ul>
<li>Kapitel 9 in <a href="https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf"><strong>Pattern Recognition and Machine Learning</strong></a> <span class="citation">(<a href="#ref-book_Bishop2006" role="doc-biblioref">Bishop 2006</a>)</span>.<br>
Die pdf-Version des Buches ist frei erhältlichen: <a href="https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf"><strong>pdf-Version</strong></a></li>
</ul>
<p>Weiteren guten Lesestoff zum EM Algoithmus gibt es z.B. hier:</p>
<ul>
<li>Kapitel 8.5 in <a href="https://web.stanford.edu/~hastie/ElemStatLearn/"><strong>Elements of Statistical Learning: Data Mining, Inference and Prediction</strong></a> <span class="citation">(<a href="#ref-Elements" role="doc-biblioref">Hastie, Tibshirani, und Friedman 2009</a>)</span>.<br>
Die pdf-Version des Buches ist frei erhältlichen: <a href="https://web.stanford.edu/~hastie/ElemStatLearn/"><strong>pdf-Version</strong></a></li>
</ul>
</div>
<div id="r-pakete-für-diese-kapitel" class="section level3 unnumbered">
<h3>R-Pakete für diese Kapitel</h3>
<p>Folgende R-Pakete werden für dieses Kapitel benötigt:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="1-der-expectation-maximization-em-algorithmus.html#cb1-1" aria-hidden="true" tabindex="-1"></a>pkgs <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;tidyverse&quot;</span>,      <span class="co"># Die tidyverse-Pakete</span></span>
<span id="cb1-2"><a href="1-der-expectation-maximization-em-algorithmus.html#cb1-2" aria-hidden="true" tabindex="-1"></a>          <span class="st">&quot;palmerpenguins&quot;</span>, <span class="co"># Pinguin-Daten</span></span>
<span id="cb1-3"><a href="1-der-expectation-maximization-em-algorithmus.html#cb1-3" aria-hidden="true" tabindex="-1"></a>          <span class="st">&quot;scales&quot;</span>,         <span class="co"># Transparente Farben: alpha()</span></span>
<span id="cb1-4"><a href="1-der-expectation-maximization-em-algorithmus.html#cb1-4" aria-hidden="true" tabindex="-1"></a>          <span class="st">&quot;RColorBrewer&quot;</span>,   <span class="co"># Hübsche Farben</span></span>
<span id="cb1-5"><a href="1-der-expectation-maximization-em-algorithmus.html#cb1-5" aria-hidden="true" tabindex="-1"></a>          <span class="st">&quot;mclust&quot;</span>,         <span class="co"># Schätzung/Verwendung </span></span>
<span id="cb1-6"><a href="1-der-expectation-maximization-em-algorithmus.html#cb1-6" aria-hidden="true" tabindex="-1"></a>                            <span class="co"># Gaußschen Mischverteilungen</span></span>
<span id="cb1-7"><a href="1-der-expectation-maximization-em-algorithmus.html#cb1-7" aria-hidden="true" tabindex="-1"></a>          <span class="st">&quot;MASS&quot;</span>)           <span class="co"># Erzeugung von Zufallszahlen aus </span></span>
<span id="cb1-8"><a href="1-der-expectation-maximization-em-algorithmus.html#cb1-8" aria-hidden="true" tabindex="-1"></a>                            <span class="co"># einer multiv. Normalverteilung</span></span>
<span id="cb1-9"><a href="1-der-expectation-maximization-em-algorithmus.html#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(pkgs)</span></code></pre></div>
<!-- ## Aufbau -->
<!-- 1. Motivation: Clusteranalyse <span style="color:#34495E">Ein Anwendungsfeld des EM Algorithmuses</span> -->
<!-- <br><br><br> -->
<!-- 2. Gaußsche Mischmodelle <span style="color:#34495E">EM Algorithmus zur Maximum-Likelihood Schätzung</span> -->
<!-- <br><br><br> -->
<!-- 3. Vervollständigung der Daten durch Latente Variablen <span style="color:#34495E">Der wahre Blick auf den EM Algorithmus</span> -->
<!-- <br><br><br> -->
<!-- 4. Zum Schluss Abstrakt<span style="color:#34495E">Die Essenz des EM Algorithmuses</span> -->
</div>
</div>
<h3>Literatur</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-book_Bishop2006" class="csl-entry">
Bishop, Christopher M. 2006. <em>Pattern Recognition and Machine Learning</em>. Springer Science &amp; Business Media.
</div>
<div id="ref-Dempster_1977" class="csl-entry">
Dempster, Arthur P, Nan M Laird, und Donald B Rubin. 1977. <span>„Maximum likelihood from incomplete data via the EM algorithm“</span>. <em>Journal of the Royal Statistical Society: Series B</em> 39 (1): 1–22.
</div>
<div id="ref-Elements" class="csl-entry">
Hastie, Trevor, Robert Tibshirani, und Jerome Friedman. 2009. <em>The Elements of Statistical Learning: Data mining, Inference, and Prediction</em>. Springer Science &amp; Business Media.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="1.1-motivation-clusteranalyse-mit-hilfe-gaußscher-mischverteilungen.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "serif",
"size": 2
},
"edit": {
"link": "https://github.com/lidom/Computational_Statistics_Script/edit/main/02-EM-Algorithmus.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Computational_Statistics_Script.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection",
"scroll_highlight": true
},
"info": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
